import streamlit as st
import pandas as pd
import utils_chamados
import google.generativeai as genai
import time

st.set_page_config(page_title="IA Analyst", page_icon="ü§ñ")

# --- CSS CHAT ---
st.markdown("""
<style>
    .stChatMessage { padding: 1rem; border-radius: 10px; margin-bottom: 10px; }
    div[data-testid="stChatMessageContent"] { font-size: 1rem; }
</style>
""", unsafe_allow_html=True)

# --- 1. CONFIGURA√á√ÉO API GOOGLE ---
api_key = st.secrets.get("GOOGLE_API_KEY")

if not api_key:
    st.error("üîë Chave GOOGLE_API_KEY n√£o configurada no secrets.toml")
    st.stop()

# Configura o Gemini (Usando a vers√£o 1.5 Flash que √© a est√°vel e gr√°tis)
genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-flash-latest')

# --- 2. CARREGAR DADOS (CONTEXTO) ---
@st.cache_data(ttl=300)
def preparar_dados_para_ia():
    df = utils_chamados.carregar_chamados_db()
    
    if df.empty:
        return "A base de dados est√° vazia."
    
    cols_uteis = ['N¬∫ Chamado', 'Projeto', 'Nome Ag√™ncia', 'Status', 'Sub-Status', 'Analista', 'Agendamento', 'Observa√ß√£o']
    cols_finais = [c for c in cols_uteis if c in df.columns]
    
    # Reduzido para 50 para economizar cota e ser mais r√°pido
    df_resumo = df[cols_finais].tail(50).copy()
    
    return df_resumo.to_csv(index=False)

dados_csv = preparar_dados_para_ia()

# --- 3. INICIALIZA HIST√ìRICO ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 4. INTERFACE ---
st.title("ü§ñ Allarmi AI Analyst")
st.caption("Pergunte sobre atrasos, status por analista ou resumos (Base: √öltimos 50 chamados).")

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 5. INTERA√á√ÉO ---
prompt = st.chat_input("Ex: Quais chamados est√£o atrasados?")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Analisando..."):
            try:
                instrucao_sistema = f"""
                Voc√™ √© um especialista em Gest√£o de Projetos.
                Use os dados CSV abaixo para responder.
                
                DADOS:
                {dados_csv}
                
                PERGUNTA:
                {prompt}
                
                Responda em portugu√™s, curto e direto.
                """
                
                response = model.generate_content(instrucao_sistema)
                texto_resposta = response.text
                
                st.markdown(texto_resposta)
                st.session_state.messages.append({"role": "assistant", "content": texto_resposta})
                
            except Exception as e:
                # Se der erro de cota de novo, avisamos de forma amig√°vel
                if "429" in str(e):
                    msg_erro = "‚è≥ **Muitas perguntas seguidas!** O plano gratuito tem um limite de velocidade. Aguarde 30 segundos e tente novamente."
                    st.warning(msg_erro)
                else:
                    st.error(f"Erro na IA: {e}")

