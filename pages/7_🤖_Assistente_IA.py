import streamlit as st
import pandas as pd
import utils_chamados
import google.generativeai as genai

st.set_page_config(page_title="IA Analyst (Gemini)", page_icon="ü§ñ")

# --- CSS CHAT ---
st.markdown("""
<style>
    .stChatMessage { padding: 1rem; border-radius: 10px; margin-bottom: 10px; }
    div[data-testid="stChatMessageContent"] { font-size: 1rem; }
</style>
""", unsafe_allow_html=True)

# --- 1. CONFIGURA√á√ÉO API GOOGLE ---
api_key = st.secrets.get("GOOGLE_API_KEY")

if not api_key:
    st.error("üîë Chave GOOGLE_API_KEY n√£o configurada no secrets.toml")
    st.stop()

# Configura o Gemini
genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-1.5-flash') # Modelo r√°pido e gr√°tis

# --- 2. CARREGAR DADOS (CONTEXTO) ---
@st.cache_data(ttl=300)
def preparar_dados_para_ia():
    df = utils_chamados.carregar_chamados_db()
    if df.empty: return "A base de dados est√° vazia."
    
    cols_uteis = ['N¬∫ Chamado', 'Projeto', 'Nome Ag√™ncia', 'Status', 'Sub-Status', 'Analista', 'Agendamento', 'Observa√ß√£o']
    cols_finais = [c for c in cols_uteis if c in df.columns]
    
    # Pega apenas os √∫ltimos 100 registros para n√£o estourar o limite de texto se for muito grande
    # ou envie tudo se o volume for pequeno. O Gemini aguenta MUITO texto (1 milh√£o de tokens).
    df_resumo = df[cols_finais].copy()
    
    return df_resumo.to_csv(index=False)

dados_csv = preparar_dados_para_ia()

# --- 3. INICIALIZA HIST√ìRICO ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    # No Gemini, o contexto inicial enviamos junto com a primeira pergunta ou configuramos o chat
    # Vamos manter simples enviando o contexto na instru√ß√£o oculta.

# --- 4. INTERFACE ---
st.title("ü§ñ Allarmi AI (Gemini Gr√°tis)")
st.caption("Pergunte sobre atrasos, status por analista ou resumos.")

# Mostra hist√≥rico
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- 5. INTERA√á√ÉO ---
prompt = st.chat_input("Ex: Quais chamados est√£o atrasados?")

if prompt:
    # A. Mostra msg do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # B. Chama o Google Gemini
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            try:
                # Monta a instru√ß√£o completa (Contexto + Pergunta)
                instrucao_sistema = f"""
                Voc√™ √© um especialista em Gest√£o de Projetos.
                Analise os dados CSV abaixo e responda √† pergunta do usu√°rio.
                
                DADOS:
                {dados_csv}
                
                PERGUNTA DO USU√ÅRIO:
                {prompt}
                
                Responda em portugu√™s, de forma direta e resumida.
                """
                
                response = model.generate_content(instrucao_sistema)
                texto_resposta = response.text
                
                st.markdown(texto_resposta)
                st.session_state.messages.append({"role": "assistant", "content": texto_resposta})
                
            except Exception as e:
                st.error(f"Erro na IA: {e}")